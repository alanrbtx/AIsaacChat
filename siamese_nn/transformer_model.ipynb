{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "    \n",
    "    positions = torch.arange(length)[:, None]\n",
    "    depth = torch.arange(depth)[None, :]/depth\n",
    "\n",
    "    angle_rates = 1/10000**depth\n",
    "    angle_rads = positions * angle_rates\n",
    "\n",
    "    pos_encoding = torch.concat(\n",
    "        [torch.sin(angle_rads), torch.cos(angle_rads)],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.positional = positional_encoding(2048, d_model)\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        length = x.shape[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= torch.math.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        print(self.positional[None, :length, :].shape)\n",
    "        x = x + self.positional[None, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/lj581pkd4_95yc_rm7yk7z4h0000gn/T/ipykernel_3360/1208820734.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(pos_encoding, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "x = PositionalEmbedding(5000, 512)(torch.randint(low=0, high=10, size=(10, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, dff, d_model):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(d_model, dff)\n",
    "        self.fc2 = torch.nn.Linear(dff, d_model)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "     \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, dff, d_model, num_heads, dropout_rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = torch.nn.MultiheadAttention(\n",
    "            embed_dim=d_model,\n",
    "            kdim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = PointWiseFeedForward(dff, d_model)\n",
    "        \n",
    "        self.layernorm1 = torch.nn.LayerNorm(normalized_shape=(10, 20, 512), eps=1e-6)\n",
    "        self.layernorm2 = torch.nn.LayerNorm(normalized_shape=(10, 20, 512), eps=1e-6)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        attn_output = self.mha(\n",
    "            key=x,\n",
    "            value=x,\n",
    "            query=x,\n",
    "        )\n",
    "        \n",
    "        out1 = self.layernorm1(attn_output[0] + x)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        \n",
    "        out2 = self.layernorm2(ffn_output + out1)\n",
    "\n",
    "        out2 = self.dropout(out2)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncoderLayer(2048, 512, 2)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, dff, num_attention_heads, num_layers, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.positional = PositionalEmbedding(vocab_size, d_model)\n",
    "        \n",
    "        self.dec_layers = [EncoderLayer(\n",
    "            d_model=d_model,\n",
    "            dff=dff,\n",
    "            num_heads=num_attention_heads\n",
    "        ) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.positional(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/lj581pkd4_95yc_rm7yk7z4h0000gn/T/ipykernel_3360/1208820734.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(pos_encoding, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4454,  0.2520,  0.2209,  ...,  0.3562,  1.0865,  1.2449],\n",
       "         [-1.3287, -0.8176, -1.3068,  ..., -0.5788,  0.6384,  0.2364],\n",
       "         [-0.5435, -0.1028, -0.2348,  ..., -0.1226,  0.0000,  1.2979],\n",
       "         ...,\n",
       "         [ 0.3918,  0.7389, -0.2951,  ...,  1.4244, -0.1599,  0.3395],\n",
       "         [ 1.3196, -0.2490, -1.3605,  ...,  0.5349, -0.0000,  1.8006],\n",
       "         [-1.3776, -0.2561,  2.2954,  ...,  0.4890, -0.1300, -1.9712]],\n",
       "\n",
       "        [[-0.4215,  0.6183,  0.2494,  ...,  0.9821,  0.3358, -0.3742],\n",
       "         [ 0.0000, -0.0000,  1.7514,  ...,  0.0894,  0.0000, -0.2292],\n",
       "         [ 0.8847, -1.5229, -0.5831,  ..., -0.6730,  0.7599, -0.9935],\n",
       "         ...,\n",
       "         [-0.2896,  0.0901,  2.3021,  ...,  2.5325,  0.0969,  0.7341],\n",
       "         [ 2.3065,  1.1182, -0.5429,  ...,  1.4037,  0.8681, -1.9225],\n",
       "         [-0.0535,  0.0000,  0.3583,  ...,  2.4435, -1.4707, -3.1531]],\n",
       "\n",
       "        [[ 2.3536, -3.5629,  0.0000,  ..., -0.0000,  2.1961, -0.0000],\n",
       "         [ 2.8880, -0.3633, -0.0762,  ..., -0.2224,  0.3386, -3.1220],\n",
       "         [ 0.0000,  0.4095,  0.0182,  ..., -0.4652, -0.7150, -0.0000],\n",
       "         ...,\n",
       "         [-1.6796, -1.4266, -0.3898,  ..., -0.0000,  0.5104, -0.0280],\n",
       "         [ 0.4840,  0.4241, -0.4522,  ..., -0.7693, -1.3620,  0.0000],\n",
       "         [-0.3190, -0.5291, -2.6780,  ..., -0.0516,  1.8172, -0.1591]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2932, -0.2264, -1.3205,  ...,  0.9823, -1.1772,  1.4350],\n",
       "         [ 0.0203,  0.6620, -1.1872,  ...,  0.1417,  0.2517, -0.6521],\n",
       "         [ 0.6206,  2.6555, -0.9226,  ..., -0.1628,  0.5347, -0.0000],\n",
       "         ...,\n",
       "         [ 0.8869,  0.9995, -0.0000,  ...,  0.5216, -0.4800,  1.0867],\n",
       "         [ 0.4939,  0.6067, -0.4161,  ..., -0.9999,  1.2463,  0.6797],\n",
       "         [ 0.3126,  0.7328,  0.9568,  ...,  1.5377,  0.7245, -2.5354]],\n",
       "\n",
       "        [[-1.3185,  0.6716, -0.0000,  ...,  1.0234, -0.3948, -0.0854],\n",
       "         [ 0.7619,  1.7878, -0.7667,  ..., -1.3247,  2.0358, -0.8521],\n",
       "         [ 0.0000,  0.9284, -0.0863,  ...,  0.4288, -1.1840,  1.7989],\n",
       "         ...,\n",
       "         [ 0.2368,  0.3119,  1.0442,  ...,  0.0000,  1.1295,  0.8197],\n",
       "         [-2.5319, -1.1462,  0.5577,  ..., -0.0000,  2.1450,  0.6419],\n",
       "         [ 0.9522, -0.2330,  0.6675,  ...,  0.6526, -0.8577, -0.6653]],\n",
       "\n",
       "        [[ 1.7824, -0.6152, -0.3928,  ...,  3.0817,  0.2311,  1.2519],\n",
       "         [ 1.6142,  0.8778,  1.7154,  ..., -0.7770,  0.6314, -1.6523],\n",
       "         [-0.0000, -0.2472, -0.2528,  ...,  0.5773, -0.0000, -0.1151],\n",
       "         ...,\n",
       "         [ 0.2799,  0.5183,  0.5694,  ...,  0.3033,  0.2115,  1.4809],\n",
       "         [-0.2758,  1.1187, -0.0000,  ...,  0.0943,  0.0490,  0.6096],\n",
       "         [-0.0000, -0.4741,  1.4887,  ...,  0.6440,  2.6913, -0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder(5000, 512, 2048, 2, 2)(torch.randint(low=0, high=5000, size=(10, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
